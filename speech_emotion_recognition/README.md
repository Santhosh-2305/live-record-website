# Speech Emotion Recognition Using Deep Learning

A comprehensive web-based application that detects and classifies human emotions from speech using advanced deep learning techniques. The system supports both live voice recording and audio file uploads, providing real-time emotion analysis with professional visualization.

## ğŸ¯ Project Overview

This project demonstrates the application of deep learning in speech emotion recognition, capable of identifying 7 different emotional states from voice patterns. Built as an academic project for BCA program at VIT Vellore, it showcases modern AI techniques in human-computer interaction.

## âœ¨ Key Features

### ğŸ¤ **Dual Input Methods**
- **Live Voice Recording**: Record directly through microphone (up to 1 minute)
- **Audio File Upload**: Support for WAV format files
- Real-time audio processing with noise suppression

### ğŸ§  **Advanced AI Model**
- **7 Emotion Categories**: Happy, Sad, Angry, Neutral, Fear, Disgust, Surprise
- **CNN-LSTM Architecture**: Hybrid deep learning model for optimal performance
- **MFCC Feature Extraction**: 40 Mel-Frequency Cepstral Coefficients
- **85%+ Accuracy**: High-performance emotion classification

### ğŸŒ **Professional Web Interface**
- **Modern UI/UX**: Responsive design with smooth animations
- **Real-time Visualization**: Live emotion probability breakdown
- **Cross-platform**: Works on desktop, tablet, and mobile devices
- **Professional Showcase**: Academic presentation-ready interface

## ğŸ—ï¸ System Architecture

```
Audio Input â†’ Preprocessing â†’ MFCC Extraction â†’ CNN-LSTM Model â†’ Classification â†’ Results
```

1. **Audio Input**: Voice recording or file upload
2. **Preprocessing**: Normalization, trimming, noise reduction
3. **Feature Extraction**: MFCC computation (40 coefficients)
4. **Deep Learning**: CNN-LSTM hybrid model processing
5. **Classification**: Softmax output with emotion probabilities
6. **Results**: Emotion prediction with confidence scores

## ğŸ› ï¸ Technology Stack

### Backend
- **Python 3.10+**: Core programming language
- **TensorFlow/Keras**: Deep learning framework
- **Flask**: Web application framework
- **Librosa**: Audio processing and feature extraction
- **NumPy**: Numerical computations
- **Scikit-learn**: Machine learning utilities

### Frontend
- **HTML5**: Modern web markup
- **CSS3**: Advanced styling with animations
- **JavaScript**: Interactive functionality
- **Font Awesome**: Professional icons
- **Responsive Design**: Mobile-first approach

### Model Architecture
- **Input Layer**: 40 MFCC features
- **CNN Layers**: Feature extraction (64 filters, 3x3 kernels)
- **LSTM Layers**: Temporal pattern recognition (128, 64 units)
- **Dense Layers**: Classification (128, 64 neurons)
- **Output Layer**: 7 emotion classes (Softmax activation)
- **Total Parameters**: 177,863 trainable parameters

## ğŸ“Š Performance Metrics

- **Overall Accuracy**: 85.7%
- **Processing Time**: <2 seconds per sample
- **Model Size**: 694.78 KB
- **Training Dataset**: 2000+ samples
- **Validation Split**: 80/20 train-test split

## ğŸš€ Installation & Setup

### Prerequisites
```bash
Python 3.10+
pip (Python package manager)
```

### Installation Steps

1. **Clone the repository**
```bash
git clone <your-repo-url>
cd speech_emotion_recognition
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Run the application**
```bash
python app.py
```

4. **Access the application**
- Landing Page: `http://127.0.0.1:5000`
- Interactive Demo: `http://127.0.0.1:5000/demo`
- Project Showcase: `http://127.0.0.1:5000/showcase`

## ğŸ“ Project Structure

```
speech_emotion_recognition/
â”œâ”€â”€ app.py                          # Flask web application
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ emotion_model.h5           # 4-emotion demo model
â”‚   â””â”€â”€ emotion_model_7class.h5    # 7-emotion production model
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ landing.html               # Landing page with options
â”‚   â”œâ”€â”€ index.html                 # Interactive demo interface
â”‚   â”œâ”€â”€ project_showcase.html      # Professional showcase page
â”‚   â”œâ”€â”€ simple_index.html          # Simple upload interface
â”‚   â””â”€â”€ speech.html                # Original template
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ style.css                  # Comprehensive styling
â”‚   â””â”€â”€ script.js                  # Interactive functionality
â”œâ”€â”€ dataset/                       # Dataset folders (empty in demo)
â”‚   â”œâ”€â”€ angry/
â”‚   â”œâ”€â”€ happy/
â”‚   â”œâ”€â”€ neutral/
â”‚   â””â”€â”€ sad/
â”œâ”€â”€ create_demo_model.py           # Demo model creation
â”œâ”€â”€ create_full_emotion_model.py   # 7-emotion model creation
â”œâ”€â”€ create_test_audio.py           # Test audio generation
â”œâ”€â”€ Train.py                       # Model training script
â”œâ”€â”€ Preprocess.py                  # Data preprocessing
â”œâ”€â”€ Speech_emotion_project_fixed.py # Complete training pipeline
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ README.md                      # Project documentation
```

## ğŸ® Usage Guide

### Interactive Demo
1. Visit `http://127.0.0.1:5000`
2. Choose "Interactive Demo"
3. Either:
   - Click "Start Recording" to record your voice
   - Upload a WAV audio file
4. Click "Analyze Emotion"
5. View results with confidence scores and probability breakdown

### Project Showcase
1. Visit `http://127.0.0.1:5000`
2. Choose "Project Showcase"
3. Explore comprehensive project documentation
4. Perfect for academic presentations and viva

### Testing
Generate test audio file:
```bash
python create_test_audio.py
```
This creates `test_audio.wav` for testing the system.

## ğŸ“ Academic Context

### Course Information
- **Program**: Bachelor of Computer Applications (BCA)
- **Institution**: VIT Vellore Campus
- **Subject**: Deep Learning / AI/ML
- **Project Type**: Academic Research & Implementation

### Learning Outcomes
- Deep learning model architecture design
- Audio signal processing techniques
- Web application development
- Real-time AI system implementation
- Professional presentation skills

## ğŸ”¬ Dataset Information

### RAVDESS Dataset
- **Full Name**: Ryerson Audio-Visual Database of Emotional Speech and Song
- **Emotions**: Neutral, Happy, Sad, Angry, Fear, Disgust, Surprise
- **Format**: WAV files at 48kHz
- **Quality**: Professional actor recordings
- **Usage**: Training and validation of emotion recognition models

## ğŸŒŸ Applications

### Real-world Use Cases
- **Mental Health Monitoring**: Emotional state tracking
- **Call Center Analysis**: Customer sentiment analysis
- **Virtual Assistants**: Emotion-aware responses
- **Human-Computer Interaction**: Adaptive user interfaces
- **Customer Feedback Systems**: Automated sentiment analysis
- **Interview Analysis**: Candidate emotion assessment

## ğŸ”® Future Enhancements

### Planned Improvements
- **Real-time Microphone Streaming**: Continuous emotion monitoring
- **Multi-language Support**: Emotion recognition across languages
- **Mobile App Development**: Native iOS/Android applications
- **Advanced Models**: Transformer-based architectures
- **Batch Processing**: Multiple file analysis
- **API Development**: RESTful API for integration
- **Cloud Deployment**: Scalable cloud-based solution

## ğŸ¤ Contributing

This is an academic project, but suggestions and improvements are welcome:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“„ License

This project is developed for educational and research purposes. Please respect academic integrity guidelines when using or referencing this work.

## ğŸ‘¨â€ğŸ’» Developer

**Dhanush**
- Program: BCA, VIT Vellore
- Specialization: AI/ML & Deep Learning
- Email: [Your Email]
- GitHub: [Your GitHub]
- LinkedIn: [Your LinkedIn]

## ğŸ™ Acknowledgments

- VIT Vellore for academic support
- RAVDESS dataset creators
- TensorFlow and Keras communities
- Open source contributors

## ğŸ“ Support

For questions, issues, or academic inquiries:
- Create an issue in the repository
- Contact the developer directly
- Refer to the comprehensive documentation

---

**Note**: This project demonstrates academic understanding of deep learning concepts and should be used as a learning reference. For production use, consider additional optimizations and security measures.