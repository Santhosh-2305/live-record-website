<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Speech Emotion Recognition - Complete Project</title>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary: #667eea;
            --secondary: #764ba2;
            --accent: #f093fb;
            --text-dark: #2d3748;
            --text-light: #718096;
            --bg-light: #f7fafc;
            --white: #ffffff;
            --success: #48bb78;
            --gradient: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            --shadow: 0 10px 25px rgba(0,0,0,0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', sans-serif;
            line-height: 1.6;
            color: var(--text-dark);
            background: var(--bg-light);
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        /* Header */
        .header {
            background: var(--white);
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            position: sticky;
            top: 0;
            z-index: 100;
        }

        .nav {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 1rem 0;
        }

        .logo {
            display: flex;
            align-items: center;
            font-size: 1.5rem;
            font-weight: 700;
            color: var(--primary);
        }

        .logo i {
            margin-right: 0.5rem;
            font-size: 1.8rem;
        }

        .nav-links {
            display: flex;
            list-style: none;
            gap: 2rem;
        }

        .nav-links a {
            text-decoration: none;
            color: var(--text-dark);
            font-weight: 500;
            transition: color 0.3s;
        }

        .nav-links a:hover {
            color: var(--primary);
        }

        /* Hero Section */
        .hero {
            background: var(--gradient);
            color: var(--white);
            padding: 4rem 0;
            text-align: center;
        }

        .hero h1 {
            font-size: 3.5rem;
            font-weight: 700;
            margin-bottom: 1rem;
        }

        .hero .subtitle {
            font-size: 1.3rem;
            margin-bottom: 2rem;
            opacity: 0.9;
            max-width: 600px;
            margin-left: auto;
            margin-right: auto;
        }

        .hero-stats {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 2rem;
            margin-top: 3rem;
        }

        .stat-card {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            padding: 1.5rem;
            border-radius: 15px;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        .stat-number {
            font-size: 2.5rem;
            font-weight: 700;
            display: block;
        }

        .stat-label {
            font-size: 0.9rem;
            opacity: 0.8;
        }
        /* Sections */
        .section {
            padding: 4rem 0;
        }

        .section-header {
            text-align: center;
            margin-bottom: 3rem;
        }

        .section-title {
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 1rem;
            color: var(--text-dark);
        }

        .section-subtitle {
            font-size: 1.2rem;
            color: var(--text-light);
            max-width: 600px;
            margin: 0 auto;
        }

        /* Demo Section */
        .demo-section {
            background: var(--white);
        }

        .demo-container {
            max-width: 800px;
            margin: 0 auto;
        }

        .input-methods {
            display: grid;
            grid-template-columns: 1fr auto 1fr;
            gap: 2rem;
            align-items: center;
            margin-bottom: 3rem;
        }

        .method-card {
            background: var(--bg-light);
            padding: 2rem;
            border-radius: 20px;
            text-align: center;
            border: 2px solid transparent;
            transition: all 0.3s;
        }

        .method-card:hover {
            border-color: var(--primary);
            transform: translateY(-5px);
        }

        .method-icon {
            font-size: 3rem;
            color: var(--primary);
            margin-bottom: 1rem;
        }

        .method-title {
            font-size: 1.3rem;
            font-weight: 600;
            margin-bottom: 0.5rem;
        }

        .method-description {
            color: var(--text-light);
            margin-bottom: 1.5rem;
        }

        .btn {
            padding: 12px 24px;
            border: none;
            border-radius: 50px;
            font-size: 1rem;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
            display: inline-flex;
            align-items: center;
            gap: 8px;
        }

        .btn-primary {
            background: var(--primary);
            color: var(--white);
        }

        .btn-primary:hover {
            background: #5a6fd8;
            transform: translateY(-2px);
        }

        .btn-record {
            background: var(--primary);
            color: var(--white);
        }

        .btn-record.recording {
            background: #e74c3c;
            animation: pulse 1s infinite;
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.05); }
        }

        .divider {
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            color: #999;
            position: relative;
        }

        .divider::before,
        .divider::after {
            content: '';
            width: 50px;
            height: 2px;
            background: #ddd;
            position: absolute;
        }

        .divider::before { left: -60px; }
        .divider::after { right: -60px; }

        .recording-indicator {
            display: none;
            align-items: center;
            gap: 10px;
            margin-top: 1rem;
            color: #e74c3c;
            font-weight: bold;
            justify-content: center;
        }

        .pulse-dot {
            width: 12px;
            height: 12px;
            background: #e74c3c;
            border-radius: 50%;
            animation: pulse 1s infinite;
        }

        #recordingTimer {
            font-family: 'Courier New', monospace;
            font-size: 1.2rem;
            font-weight: bold;
            background: rgba(231, 76, 60, 0.1);
            padding: 4px 8px;
            border-radius: 6px;
            border: 1px solid #e74c3c;
            min-width: 50px;
            text-align: center;
        }

        .file-name {
            margin-top: 1rem;
            color: var(--primary);
            font-weight: bold;
        }

        .analyze-section {
            text-align: center;
            margin-bottom: 3rem;
        }

        .btn-analyze {
            background: var(--success);
            color: var(--white);
            font-size: 1.1rem;
            padding: 15px 30px;
        }

        .btn-analyze:hover:not(:disabled) {
            background: #38a169;
        }

        .btn-analyze:disabled {
            background: #ccc;
            cursor: not-allowed;
        }

        .loading {
            display: none;
            text-align: center;
            padding: 2rem;
        }

        .spinner {
            width: 50px;
            height: 50px;
            border: 5px solid #f3f3f3;
            border-top: 5px solid var(--primary);
            border-radius: 50%;
            animation: spin 1s linear infinite;
            margin: 0 auto 1rem;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        /* Results */
        .result-section {
            display: none;
            background: var(--white);
            border-radius: 20px;
            padding: 2rem;
            box-shadow: var(--shadow);
            margin-top: 2rem;
        }

        .emotion-result {
            display: flex;
            align-items: center;
            gap: 2rem;
            margin-bottom: 2rem;
            padding: 1.5rem;
            background: var(--bg-light);
            border-radius: 15px;
        }

        .emotion-emoji {
            font-size: 4rem;
        }

        .emotion-details h4 {
            font-size: 2rem;
            margin-bottom: 1rem;
        }

        .confidence-bar {
            width: 200px;
            height: 10px;
            background: #e9ecef;
            border-radius: 5px;
            overflow: hidden;
            margin-bottom: 0.5rem;
        }

        .confidence-fill {
            height: 100%;
            background: var(--gradient);
            transition: width 0.5s ease;
        }

        .confidence-text {
            font-weight: bold;
            color: var(--success);
        }

        .emotion-breakdown {
            margin-top: 2rem;
        }

        .emotion-bars {
            display: grid;
            gap: 1rem;
        }

        .emotion-bar {
            display: grid;
            grid-template-columns: 100px 1fr 60px;
            align-items: center;
            gap: 1rem;
        }

        .bar {
            height: 20px;
            background: #e9ecef;
            border-radius: 10px;
            overflow: hidden;
        }

        .fill {
            height: 100%;
            background: var(--gradient);
            transition: width 0.5s ease;
            width: 0%;
        }

        .percentage {
            text-align: right;
            font-weight: bold;
            color: var(--primary);
        }
        /* Features Grid */
        .features-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 2rem;
            margin-top: 3rem;
        }

        .feature-card {
            background: var(--white);
            padding: 2rem;
            border-radius: 20px;
            box-shadow: var(--shadow);
            transition: transform 0.3s;
            border: 1px solid rgba(102, 126, 234, 0.1);
        }

        .feature-card:hover {
            transform: translateY(-5px);
        }

        .feature-icon {
            width: 60px;
            height: 60px;
            background: var(--gradient);
            border-radius: 15px;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 1.5rem;
            color: var(--white);
            font-size: 1.5rem;
        }

        .feature-title {
            font-size: 1.3rem;
            font-weight: 600;
            margin-bottom: 1rem;
        }

        .feature-description {
            color: var(--text-light);
        }

        /* Architecture Flow */
        .architecture-flow {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1.5rem;
            margin-top: 3rem;
        }

        .flow-step {
            background: var(--white);
            padding: 2rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: var(--shadow);
            position: relative;
            transition: transform 0.3s;
        }

        .flow-step:hover {
            transform: translateY(-3px);
        }

        .flow-step::after {
            content: '‚Üí';
            position: absolute;
            right: -1rem;
            top: 50%;
            transform: translateY(-50%);
            font-size: 1.5rem;
            color: var(--primary);
            font-weight: bold;
        }

        .flow-step:last-child::after {
            display: none;
        }

        .step-number {
            width: 40px;
            height: 40px;
            background: var(--gradient);
            color: var(--white);
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 0 auto 1rem;
            font-weight: 600;
        }

        .step-title {
            font-size: 1.1rem;
            font-weight: 600;
            margin-bottom: 0.5rem;
        }

        .step-description {
            font-size: 0.9rem;
            color: var(--text-light);
        }

        /* Tech Stack */
        .tech-stack {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 1.5rem;
            margin-top: 3rem;
        }

        .tech-item {
            background: var(--white);
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 2px 10px rgba(0,0,0,0.05);
            transition: transform 0.3s;
        }

        .tech-item:hover {
            transform: translateY(-3px);
        }

        .tech-icon {
            font-size: 2.5rem;
            margin-bottom: 1rem;
            color: var(--primary);
        }

        .tech-name {
            font-weight: 600;
        }

        /* Results Grid */
        .results-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 2rem;
            margin-top: 3rem;
        }

        .result-card {
            background: var(--white);
            padding: 2rem;
            border-radius: 20px;
            text-align: center;
            box-shadow: var(--shadow);
        }

        .result-icon {
            width: 80px;
            height: 80px;
            background: var(--gradient);
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 0 auto 1.5rem;
            color: var(--white);
            font-size: 2rem;
        }

        .result-title {
            font-size: 1.2rem;
            font-weight: 600;
            margin-bottom: 1rem;
        }

        .result-value {
            font-size: 2rem;
            font-weight: 700;
            color: var(--primary);
            margin-bottom: 0.5rem;
        }

        .result-description {
            color: var(--text-light);
            font-size: 0.9rem;
        }

        /* Footer */
        .footer {
            background: var(--text-dark);
            color: var(--white);
            padding: 3rem 0 1rem;
        }

        .footer-content {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 2rem;
            margin-bottom: 2rem;
        }

        .footer-section h3 {
            margin-bottom: 1rem;
            color: var(--primary);
        }

        .footer-section p, .footer-section li {
            color: rgba(255, 255, 255, 0.8);
            margin-bottom: 0.5rem;
        }

        .footer-section ul {
            list-style: none;
        }

        .footer-bottom {
            text-align: center;
            padding-top: 2rem;
            border-top: 1px solid rgba(255, 255, 255, 0.1);
            color: rgba(255, 255, 255, 0.6);
        }

        /* Responsive */
        @media (max-width: 768px) {
            .hero h1 { font-size: 2.5rem; }
            .input-methods { grid-template-columns: 1fr; }
            .divider::before, .divider::after { display: none; }
            .emotion-result { flex-direction: column; text-align: center; }
            .nav-links { display: none; }
            .architecture-flow .flow-step::after {
                content: '‚Üì';
                right: 50%;
                top: 100%;
                transform: translateX(50%);
            }
        }
    </style>
</head>
<body>
    <!-- Header -->
    <header class="header">
        <nav class="nav container">
            <div class="logo">
                <i class="fas fa-microphone-alt"></i>
                SpeechEmotion AI
            </div>
            <ul class="nav-links">
                <li><a href="#demo">Demo</a></li>
                <li><a href="#features">Features</a></li>
                <li><a href="#architecture">Architecture</a></li>
                <li><a href="#results">Results</a></li>
                <li><a href="#technology">Technology</a></li>
            </ul>
        </nav>
    </header>

    <!-- Hero Section -->
    <section class="hero">
        <div class="container">
            <h1>Speech Emotion Recognition</h1>
            <p class="subtitle">
                Advanced AI system that detects and classifies human emotions from speech using deep learning. 
                Supports live voice recording and audio file analysis with 7 emotion categories.
            </p>
            <div class="hero-stats">
                <div class="stat-card">
                    <span class="stat-number">7</span>
                    <span class="stat-label">Emotion Categories</span>
                </div>
                <div class="stat-card">
                    <span class="stat-number">85%+</span>
                    <span class="stat-label">Accuracy Rate</span>
                </div>
                <div class="stat-card">
                    <span class="stat-number">1 Min</span>
                    <span class="stat-label">Max Recording</span>
                </div>
                <div class="stat-card">
                    <span class="stat-number">Real-time</span>
                    <span class="stat-label">Processing</span>
                </div>
            </div>
        </div>
    </section>

    <!-- Interactive Demo Section -->
    <section id="demo" class="section demo-section">
        <div class="container">
            <div class="section-header">
                <h2 class="section-title">Interactive Demo</h2>
                <p class="section-subtitle">
                    Try our emotion recognition system! Record your voice or upload an audio file to see AI in action.
                </p>
            </div>
            <div class="demo-container">
                <div class="input-methods">
                    <div class="method-card">
                        <div class="method-icon">
                            <i class="fas fa-cloud-upload-alt"></i>
                        </div>
                        <h3 class="method-title">Upload Audio File</h3>
                        <p class="method-description">Choose audio files: WAV, MP3, or MP4</p>
                        <input type="file" id="audioFile" accept="audio/wav,audio/mp3,audio/mpeg,audio/mp4,audio/*" style="display: none;">
                        <button class="btn btn-primary" onclick="document.getElementById('audioFile').click()">
                            <i class="fas fa-upload"></i>
                            Choose File
                        </button>
                        <div id="fileName" class="file-name"></div>
                    </div>
                    
                    <div class="divider">
                        <span>OR</span>
                    </div>
                    
                    <div class="method-card">
                        <div class="method-icon">
                            <i class="fas fa-microphone"></i>
                        </div>
                        <h3 class="method-title">Record Voice</h3>
                        <p class="method-description">Record your voice for up to 1 minute</p>
                        <button class="btn btn-record" id="recordBtn">
                            <i class="fas fa-microphone"></i>
                            <span id="recordText">Start Recording</span>
                        </button>
                        <div class="recording-indicator" id="recordingIndicator">
                            <div class="pulse-dot"></div>
                            <span>Recording...</span>
                            <div id="recordingTimer" style="margin-left: 10px; font-weight: bold; color: #e74c3c;">00:00</div>
                        </div>
                        <div style="margin-top: 1rem;">
                            <button class="btn" id="testMicBtn" style="background: #17a2b8; color: white; font-size: 0.9rem; padding: 8px 16px;">
                                <i class="fas fa-volume-up"></i>
                                Test Microphone
                            </button>
                        </div>
                    </div>
                </div>
                
                <div class="analyze-section">
                    <button class="btn btn-analyze" id="analyzeBtn" disabled>
                        <i class="fas fa-brain"></i>
                        Analyze Emotion
                    </button>
                    <div class="loading" id="loadingIndicator">
                        <div class="spinner"></div>
                        <p>Analyzing your voice...</p>
                    </div>
                </div>
                
                <div class="result-section" id="resultSection">
                    <h3 style="text-align: center; margin-bottom: 2rem;">Emotion Analysis Result</h3>
                    <div class="emotion-result">
                        <div class="emotion-emoji" id="emotionEmoji">üòä</div>
                        <div class="emotion-details">
                            <h4 id="emotionName">Happy</h4>
                            <div class="confidence-bar">
                                <div class="confidence-fill" id="confidenceFill"></div>
                            </div>
                            <p class="confidence-text">Confidence: <span id="confidenceScore">85%</span></p>
                        </div>
                    </div>
                    
                    <div class="emotion-breakdown">
                        <h4>Emotion Breakdown</h4>
                        <div class="emotion-bars">
                            <div class="emotion-bar">
                                <span>üòê Neutral</span>
                                <div class="bar"><div class="fill" data-emotion="neutral"></div></div>
                                <span class="percentage" data-emotion="neutral">0%</span>
                            </div>
                            <div class="emotion-bar">
                                <span>üòä Happy</span>
                                <div class="bar"><div class="fill" data-emotion="happy"></div></div>
                                <span class="percentage" data-emotion="happy">0%</span>
                            </div>
                            <div class="emotion-bar">
                                <span>üò¢ Sad</span>
                                <div class="bar"><div class="fill" data-emotion="sad"></div></div>
                                <span class="percentage" data-emotion="sad">0%</span>
                            </div>
                            <div class="emotion-bar">
                                <span>üò° Angry</span>
                                <div class="bar"><div class="fill" data-emotion="angry"></div></div>
                                <span class="percentage" data-emotion="angry">0%</span>
                            </div>
                            <div class="emotion-bar">
                                <span>üò® Fear</span>
                                <div class="bar"><div class="fill" data-emotion="fear"></div></div>
                                <span class="percentage" data-emotion="fear">0%</span>
                            </div>
                            <div class="emotion-bar">
                                <span>ü§¢ Disgust</span>
                                <div class="bar"><div class="fill" data-emotion="disgust"></div></div>
                                <span class="percentage" data-emotion="disgust">0%</span>
                            </div>
                            <div class="emotion-bar">
                                <span>üò≤ Surprise</span>
                                <div class="bar"><div class="fill" data-emotion="surprise"></div></div>
                                <span class="percentage" data-emotion="surprise">0%</span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- Features Section -->
    <section id="features" class="section">
        <div class="container">
            <div class="section-header">
                <h2 class="section-title">Project Features</h2>
                <p class="section-subtitle">
                    Comprehensive deep learning solution for emotion recognition from speech signals
                </p>
            </div>
            <div class="features-grid">
                <div class="feature-card">
                    <div class="feature-icon">
                        <i class="fas fa-microphone"></i>
                    </div>
                    <h3 class="feature-title">Live Voice Recording</h3>
                    <p class="feature-description">
                        Record voice directly through microphone for up to 1 minute with real-time audio capture and noise suppression.
                    </p>
                </div>
                <div class="feature-card">
                    <div class="feature-icon">
                        <i class="fas fa-upload"></i>
                    </div>
                    <h3 class="feature-title">Audio File Upload</h3>
                    <p class="feature-description">
                        Support for WAV audio file uploads with automatic preprocessing and feature extraction.
                    </p>
                </div>
                <div class="feature-card">
                    <div class="feature-icon">
                        <i class="fas fa-brain"></i>
                    </div>
                    <h3 class="feature-title">Deep Learning Model</h3>
                    <p class="feature-description">
                        CNN-LSTM hybrid architecture trained on RAVDESS dataset for accurate emotion classification.
                    </p>
                </div>
                <div class="feature-card">
                    <div class="feature-icon">
                        <i class="fas fa-chart-bar"></i>
                    </div>
                    <h3 class="feature-title">7 Emotion Categories</h3>
                    <p class="feature-description">
                        Classifies Happy, Sad, Angry, Neutral, Fear, Disgust, and Surprise with confidence scores.
                    </p>
                </div>
                <div class="feature-card">
                    <div class="feature-icon">
                        <i class="fas fa-wave-square"></i>
                    </div>
                    <h3 class="feature-title">MFCC Feature Extraction</h3>
                    <p class="feature-description">
                        Mel-Frequency Cepstral Coefficients extraction for capturing essential speech characteristics.
                    </p>
                </div>
                <div class="feature-card">
                    <div class="feature-icon">
                        <i class="fas fa-globe"></i>
                    </div>
                    <h3 class="feature-title">Web-Based Interface</h3>
                    <p class="feature-description">
                        Modern, responsive web interface built with Flask for cross-platform compatibility.
                    </p>
                </div>
            </div>
        </div>
    </section>

    <!-- Architecture Section -->
    <section id="architecture" class="section" style="background: var(--white);">
        <div class="container">
            <div class="section-header">
                <h2 class="section-title">System Architecture</h2>
                <p class="section-subtitle">
                    End-to-end pipeline from audio input to emotion prediction using advanced signal processing
                </p>
            </div>
            <div class="architecture-flow">
                <div class="flow-step">
                    <div class="step-number">1</div>
                    <h3 class="step-title">Audio Input</h3>
                    <p class="step-description">Voice recording via microphone or WAV file upload</p>
                </div>
                <div class="flow-step">
                    <div class="step-number">2</div>
                    <h3 class="step-title">Preprocessing</h3>
                    <p class="step-description">Audio normalization, trimming, and noise reduction</p>
                </div>
                <div class="flow-step">
                    <div class="step-number">3</div>
                    <h3 class="step-title">Feature Extraction</h3>
                    <p class="step-description">MFCC computation with 40 coefficients per frame</p>
                </div>
                <div class="flow-step">
                    <div class="step-number">4</div>
                    <h3 class="step-title">Deep Learning</h3>
                    <p class="step-description">CNN-LSTM model processes extracted features</p>
                </div>
                <div class="flow-step">
                    <div class="step-number">5</div>
                    <h3 class="step-title">Classification</h3>
                    <p class="step-description">Softmax output with emotion probabilities</p>
                </div>
                <div class="flow-step">
                    <div class="step-number">6</div>
                    <h3 class="step-title">Result Display</h3>
                    <p class="step-description">Emotion prediction with confidence scores</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Results Section -->
    <section id="results" class="section">
        <div class="container">
            <div class="section-header">
                <h2 class="section-title">Performance Results</h2>
                <p class="section-subtitle">
                    Comprehensive evaluation metrics demonstrating the effectiveness of our approach
                </p>
            </div>
            <div class="results-grid">
                <div class="result-card">
                    <div class="result-icon">
                        <i class="fas fa-bullseye"></i>
                    </div>
                    <h3 class="result-title">Overall Accuracy</h3>
                    <div class="result-value">85.7%</div>
                    <p class="result-description">Average classification accuracy across all emotion categories</p>
                </div>
                <div class="result-card">
                    <div class="result-icon">
                        <i class="fas fa-database"></i>
                    </div>
                    <h3 class="result-title">Dataset Size</h3>
                    <div class="result-value">2000+</div>
                    <p class="result-description">Training samples from RAVDESS emotional speech database</p>
                </div>
                <div class="result-card">
                    <div class="result-icon">
                        <i class="fas fa-clock"></i>
                    </div>
                    <h3 class="result-title">Processing Time</h3>
                    <div class="result-value">&lt;2s</div>
                    <p class="result-description">Average time for emotion prediction per audio sample</p>
                </div>
                <div class="result-card">
                    <div class="result-icon">
                        <i class="fas fa-layer-group"></i>
                    </div>
                    <h3 class="result-title">Model Parameters</h3>
                    <div class="result-value">177K</div>
                    <p class="result-description">Total trainable parameters in the neural network</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Technology Section -->
    <section id="technology" class="section" style="background: var(--white);">
        <div class="container">
            <div class="section-header">
                <h2 class="section-title">Technology Stack</h2>
                <p class="section-subtitle">
                    Modern technologies and frameworks powering our speech emotion recognition system
                </p>
            </div>
            <div class="tech-stack">
                <div class="tech-item">
                    <div class="tech-icon">üêç</div>
                    <div class="tech-name">Python</div>
                </div>
                <div class="tech-item">
                    <div class="tech-icon">üß†</div>
                    <div class="tech-name">TensorFlow</div>
                </div>
                <div class="tech-item">
                    <div class="tech-icon">‚ö°</div>
                    <div class="tech-name">Keras</div>
                </div>
                <div class="tech-item">
                    <div class="tech-icon">üéµ</div>
                    <div class="tech-name">Librosa</div>
                </div>
                <div class="tech-item">
                    <div class="tech-icon">üåê</div>
                    <div class="tech-name">Flask</div>
                </div>
                <div class="tech-item">
                    <div class="tech-icon">üìä</div>
                    <div class="tech-name">NumPy</div>
                </div>
                <div class="tech-item">
                    <div class="tech-icon">üî¨</div>
                    <div class="tech-name">Scikit-learn</div>
                </div>
                <div class="tech-item">
                    <div class="tech-icon">üíª</div>
                    <div class="tech-name">JavaScript</div>
                </div>
            </div>
        </div>
    </section>
    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <div class="footer-content">
                <div class="footer-section">
                    <h3>Project Information</h3>
                    <p>Speech Emotion Recognition using Deep Learning</p>
                    <p>Academic Project - BCA Program</p>
                    <p>VIT Vellore Campus</p>
                </div>
                <div class="footer-section">
                    <h3>Key Features</h3>
                    <ul>
                        <li>Live voice recording (1 minute max)</li>
                        <li>Audio file upload support</li>
                        <li>7 emotion categories</li>
                        <li>Real-time processing</li>
                        <li>85%+ accuracy rate</li>
                    </ul>
                </div>
                <div class="footer-section">
                    <h3>Technologies Used</h3>
                    <ul>
                        <li>Python & TensorFlow</li>
                        <li>CNN-LSTM Architecture</li>
                        <li>MFCC Feature Extraction</li>
                        <li>RAVDESS Dataset</li>
                        <li>Flask Web Framework</li>
                    </ul>
                </div>
                <div class="footer-section">
                    <h3>Applications</h3>
                    <ul>
                        <li>Mental health monitoring</li>
                        <li>Call center analysis</li>
                        <li>Virtual assistants</li>
                        <li>Human-computer interaction</li>
                        <li>Customer feedback systems</li>
                    </ul>
                </div>
            </div>
            <div class="footer-bottom">
                <p>&copy; 2024 Speech Emotion Recognition Project. Developed for academic research and demonstration.</p>
            </div>
        </div>
    </footer>

    <script>
        // Global variables
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;
        let recordedBlob = null;
        let uploadedFile = null;
        let recordingStartTime = null;
        let recordingTimer = null;

        // DOM elements
        const recordBtn = document.getElementById('recordBtn');
        const recordText = document.getElementById('recordText');
        const recordingIndicator = document.getElementById('recordingIndicator');
        const recordingTimerDisplay = document.getElementById('recordingTimer');
        const analyzeBtn = document.getElementById('analyzeBtn');
        const audioFileInput = document.getElementById('audioFile');
        const fileName = document.getElementById('fileName');
        const loadingIndicator = document.getElementById('loadingIndicator');
        const resultSection = document.getElementById('resultSection');
        const testMicBtn = document.getElementById('testMicBtn');

        // Initialize
        document.addEventListener('DOMContentLoaded', function() {
            initializeEventListeners();
            hideElements();
        });

        function initializeEventListeners() {
            if (recordBtn) recordBtn.addEventListener('click', toggleRecording);
            if (audioFileInput) audioFileInput.addEventListener('change', handleFileUpload);
            if (analyzeBtn) analyzeBtn.addEventListener('click', analyzeEmotion);
            if (testMicBtn) testMicBtn.addEventListener('click', testMicrophone);
        }

        function hideElements() {
            if (recordingIndicator) recordingIndicator.style.display = 'none';
            if (recordingTimerDisplay) recordingTimerDisplay.textContent = '00:00';
            if (loadingIndicator) loadingIndicator.style.display = 'none';
            if (resultSection) resultSection.style.display = 'none';
        }

        async function toggleRecording() {
            if (!isRecording) {
                await startRecording();
            } else {
                stopRecording();
            }
        }

        async function startRecording() {
            try {
                // Request microphone permission
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    } 
                });
                
                // Check supported MIME types
                let mimeType = 'audio/webm';
                if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
                    mimeType = 'audio/webm;codecs=opus';
                } else if (MediaRecorder.isTypeSupported('audio/mp4')) {
                    mimeType = 'audio/mp4';
                } else if (MediaRecorder.isTypeSupported('audio/wav')) {
                    mimeType = 'audio/wav';
                }
                
                console.log('Using MIME type:', mimeType);
                
                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: mimeType
                });
                
                audioChunks = [];
                
                mediaRecorder.ondataavailable = (event) => {
                    console.log('Data available:', event.data.size);
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };
                
                mediaRecorder.onstop = () => {
                    console.log('Recording stopped, chunks:', audioChunks.length);
                    recordedBlob = new Blob(audioChunks, { type: mimeType });
                    console.log('Recorded blob size:', recordedBlob.size);
                    uploadedFile = null;
                    enableAnalyzeButton();
                    
                    // Stop all tracks to release microphone
                    stream.getTracks().forEach(track => track.stop());
                };
                
                mediaRecorder.onerror = (event) => {
                    console.error('MediaRecorder error:', event.error);
                    alert('Recording error: ' + event.error);
                };
                
                mediaRecorder.start(1000); // Collect data every second
                isRecording = true;
                recordingStartTime = Date.now();
                
                console.log('Recording started');
                
                // Update UI
                recordText.textContent = 'Stop Recording';
                recordBtn.classList.add('recording');
                recordingIndicator.style.display = 'flex';
                
                // Start the timer
                startRecordingTimer();
                
                // Auto-stop after 60 seconds
                setTimeout(() => {
                    if (isRecording) {
                        console.log('Auto-stopping recording after 60 seconds');
                        stopRecording();
                    }
                }, 60000);
                
            } catch (error) {
                console.error('Error accessing microphone:', error);
                let errorMessage = 'Error accessing microphone. ';
                
                if (error.name === 'NotAllowedError') {
                    errorMessage += 'Please allow microphone access and try again.';
                } else if (error.name === 'NotFoundError') {
                    errorMessage += 'No microphone found. Please check your device.';
                } else if (error.name === 'NotSupportedError') {
                    errorMessage += 'Your browser does not support audio recording.';
                } else {
                    errorMessage += error.message;
                }
                
                alert(errorMessage);
            }
        }

        function stopRecording() {
            if (mediaRecorder && isRecording) {
                console.log('Stopping recording...');
                mediaRecorder.stop();
                isRecording = false;
                
                // Stop the timer
                stopRecordingTimer();
                
                // Update UI
                recordText.textContent = 'Start Recording';
                recordBtn.classList.remove('recording');
                recordingIndicator.style.display = 'none';
                recordingTimerDisplay.textContent = '00:00';
            }
        }

        function handleFileUpload(event) {
            const file = event.target.files[0];
            if (file) {
                uploadedFile = file;
                recordedBlob = null;
                fileName.textContent = file.name;
                enableAnalyzeButton();
            }
        }

        function enableAnalyzeButton() {
            if (analyzeBtn) {
                analyzeBtn.disabled = false;
                analyzeBtn.style.background = 'var(--success)';
            }
        }

        async function analyzeEmotion() {
            if (!recordedBlob && !uploadedFile) {
                alert('Please record audio or upload a file first.');
                return;
            }
            
            console.log('Starting analysis...');
            console.log('Recorded blob:', recordedBlob ? recordedBlob.size + ' bytes' : 'none');
            console.log('Uploaded file:', uploadedFile ? uploadedFile.name : 'none');
            
            loadingIndicator.style.display = 'block';
            resultSection.style.display = 'none';
            analyzeBtn.disabled = true;
            
            try {
                const formData = new FormData();
                
                if (recordedBlob) {
                    // Create a file from the blob with proper extension
                    const audioFile = new File([recordedBlob], 'recording.webm', { 
                        type: recordedBlob.type 
                    });
                    formData.append('audio', audioFile);
                    console.log('Sending recorded audio:', audioFile.name, audioFile.size, 'bytes');
                } else if (uploadedFile) {
                    formData.append('audio', uploadedFile);
                    console.log('Sending uploaded file:', uploadedFile.name, uploadedFile.size, 'bytes');
                }
                
                console.log('Making request to /predict...');
                const response = await fetch('/predict', {
                    method: 'POST',
                    body: formData
                });
                
                console.log('Response status:', response.status);
                
                if (!response.ok) {
                    throw new Error(`Server error: ${response.status} ${response.statusText}`);
                }
                
                const result = await response.json();
                console.log('Response data:', result);
                
                if (result.success) {
                    displayResult(result);
                } else {
                    throw new Error(result.error || 'Analysis failed');
                }
                
            } catch (error) {
                console.error('Error analyzing emotion:', error);
                
                let errorMessage = 'Error analyzing emotion: ';
                if (error.message.includes('Failed to fetch')) {
                    errorMessage += 'Connection failed. Please check if the server is running.';
                } else if (error.message.includes('Server error: 500')) {
                    errorMessage += 'Server processing error. The audio format might not be supported. Try uploading a WAV file.';
                } else {
                    errorMessage += error.message;
                }
                
                alert(errorMessage);
            } finally {
                loadingIndicator.style.display = 'none';
                analyzeBtn.disabled = false;
            }
        }

        function displayResult(result) {
            const emotionEmoji = document.getElementById('emotionEmoji');
            const emotionName = document.getElementById('emotionName');
            const confidenceScore = document.getElementById('confidenceScore');
            const confidenceFill = document.getElementById('confidenceFill');
            
            const emojiMap = {
                'Happy': 'üòä', 'Sad': 'üò¢', 'Angry': 'üò°', 'Neutral': 'üòê',
                'Fear': 'üò®', 'Disgust': 'ü§¢', 'Surprise': 'üò≤'
            };
            
            if (emotionEmoji) emotionEmoji.textContent = emojiMap[result.emotion] || 'üòê';
            if (emotionName) emotionName.textContent = result.emotion;
            if (confidenceScore) confidenceScore.textContent = result.confidence + '%';
            if (confidenceFill) confidenceFill.style.width = result.confidence + '%';
            
            if (result.probabilities) {
                updateEmotionBreakdown(result.probabilities);
            }
            
            resultSection.style.display = 'block';
            resultSection.scrollIntoView({ behavior: 'smooth' });
        }

        function updateEmotionBreakdown(probabilities) {
            const emotions = ['neutral', 'happy', 'sad', 'angry', 'fear', 'disgust', 'surprise'];
            
            emotions.forEach(emotion => {
                const fill = document.querySelector(`[data-emotion="${emotion}"] .fill`);
                const percentage = document.querySelector(`[data-emotion="${emotion}"] .percentage`);
                
                if (fill && percentage && probabilities[emotion] !== undefined) {
                    const value = Math.round(probabilities[emotion] * 100);
                    fill.style.width = value + '%';
                    percentage.textContent = value + '%';
                }
            });
        }

        // Smooth scrolling
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) {
                    target.scrollIntoView({ behavior: 'smooth' });
                }
            });
        });

        // Test microphone function
        async function testMicrophone() {
            try {
                console.log('Testing microphone access...');
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                // Success - microphone is accessible
                alert('‚úÖ Microphone access successful! You can now record audio.');
                
                // Stop the stream
                stream.getTracks().forEach(track => track.stop());
                
            } catch (error) {
                console.error('Microphone test failed:', error);
                let errorMessage = '‚ùå Microphone test failed: ';
                
                if (error.name === 'NotAllowedError') {
                    errorMessage += 'Permission denied. Please allow microphone access in your browser settings.';
                } else if (error.name === 'NotFoundError') {
                    errorMessage += 'No microphone found. Please check your device.';
                } else if (error.name === 'NotSupportedError') {
                    errorMessage += 'Your browser does not support audio recording.';
                } else {
                    errorMessage += error.message;
                }
                
                alert(errorMessage);
            }
        }

        // Recording timer functions
        function startRecordingTimer() {
            recordingTimer = setInterval(updateRecordingTimer, 100); // Update every 100ms for smooth display
        }

        function stopRecordingTimer() {
            if (recordingTimer) {
                clearInterval(recordingTimer);
                recordingTimer = null;
            }
        }

        function updateRecordingTimer() {
            if (recordingStartTime && isRecording) {
                const elapsed = Date.now() - recordingStartTime;
                const seconds = Math.floor(elapsed / 1000);
                const minutes = Math.floor(seconds / 60);
                const remainingSeconds = seconds % 60;
                
                // Format as MM:SS
                const formattedTime = `${minutes.toString().padStart(2, '0')}:${remainingSeconds.toString().padStart(2, '0')}`;
                
                if (recordingTimerDisplay) {
                    recordingTimerDisplay.textContent = formattedTime;
                    
                    // Change color as we approach the 1-minute limit
                    if (seconds >= 50) {
                        recordingTimerDisplay.style.color = '#ff4444'; // Red when close to limit
                    } else if (seconds >= 40) {
                        recordingTimerDisplay.style.color = '#ff8800'; // Orange warning
                    } else {
                        recordingTimerDisplay.style.color = '#e74c3c'; // Default red
                    }
                }
            }
        }
    </script>
</body>
</html>